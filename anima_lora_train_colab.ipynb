{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41f03324",
   "metadata": {},
   "source": [
    "# ğŸ¨ Anima LoRA Training (diffusion-pipe / Colab T4)\n",
    "\n",
    "> **Anima** â€” 2B parameter anime-focused text-to-image model (Cosmos-Predict2 ê¸°ë°˜, CircleStone Labs)\n",
    ">\n",
    "> [diffusion-pipe](https://github.com/tdrussell/diffusion-pipe)ë¥¼ ì´ìš©í•œ DeepSpeed ê¸°ë°˜ LoRA í•™ìŠµ ë…¸íŠ¸ë¶\n",
    ">\n",
    "> **í™˜ê²½:** Colab T4 (16GB VRAM) / bf16 / Prodigy / rank 16\n",
    ">\n",
    "> ì£¼ìš” í•˜ì´í¼íŒŒë¼ë¯¸í„°ëŠ” ì…€ 4-1, 4-2ì˜ `@param` í¼ì—ì„œ ì¡°ì ˆ ê°€ëŠ¥í•©ë‹ˆë‹¤.\n",
    "\n",
    "### ê³ ì • ì„¤ì • (ë³€ê²½ ë¹„ê¶Œì¥)\n",
    "| í•­ëª© | ê°’ | ì´ìœ  |\n",
    "|---|---|---|\n",
    "| dtype | `bfloat16` | PyTorch 2.9+ì—ì„œ T4 bf16 ì§€ì›, fp16ì€ NaN ìœ„í—˜ |\n",
    "| pipeline_stages | 1 | LoRA í•™ìŠµì—ì„œëŠ” 1 ê³ ì • |\n",
    "| activation_checkpointing | true | T4 VRAM í•„ìˆ˜ |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989c9b60",
   "metadata": {},
   "source": [
    "## 1. í™˜ê²½ ì„¤ì • ë° ì˜ì¡´ì„± ì„¤ì¹˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564c5279",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 1-1. GPU í™•ì¸ ë° CUDA ë©”ëª¨ë¦¬ ì„¤ì •\n",
    "import torch, subprocess\n",
    "\n",
    "# GPU í™•ì¸\n",
    "gpu_name = torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"NO GPU\"\n",
    "gpu_mem = torch.cuda.get_device_properties(0).total_memory / 1024**3 if torch.cuda.is_available() else 0\n",
    "print(f\"ğŸ–¥ï¸  GPU: {gpu_name}\")\n",
    "print(f\"ğŸ’¾ VRAM: {gpu_mem:.1f} GB\")\n",
    "print(f\"ğŸ”§ CUDA: {torch.version.cuda}\")\n",
    "print(f\"ğŸ PyTorch: {torch.__version__}\")\n",
    "\n",
    "# bf16 ì§€ì› ì—¬ë¶€ í™•ì¸\n",
    "bf16_support = torch.cuda.is_bf16_supported()\n",
    "print(f\"ğŸ“‹ BF16 ì§€ì›: {bf16_support}\")\n",
    "if bf16_support:\n",
    "    print(\"   â†’ BF16 ëª¨ë“œë¡œ í•™ìŠµí•©ë‹ˆë‹¤\")\n",
    "else:\n",
    "    print(\"   âš ï¸ BF16 ë¯¸ì§€ì› â€” TOMLì—ì„œ dtypeì„ float16ìœ¼ë¡œ ìˆ˜ì • í•„ìš”\")\n",
    "\n",
    "# CUDA ë©”ëª¨ë¦¬ ë‹¨í¸í™” ë°©ì§€\n",
    "import os\n",
    "os.environ['PYTORCH_ALLOC_CONF'] = 'expandable_segments:True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c1b158",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 1-2. diffusion-pipe í´ë¡  ë° ì˜ì¡´ì„± ì„¤ì¹˜\n",
    "import os\n",
    "\n",
    "# diffusion-pipe í´ë¡  (ComfyUI ë“± submodule í¬í•¨ í•„ìˆ˜!)\n",
    "if not os.path.exists('/content/diffusion-pipe'):\n",
    "    !git clone --recurse-submodules https://github.com/tdrussell/diffusion-pipe.git /content/diffusion-pipe\n",
    "else:\n",
    "    print(\"diffusion-pipe already cloned\")\n",
    "\n",
    "os.chdir('/content/diffusion-pipe')\n",
    "\n",
    "# submoduleì´ ë¹„ì–´ìˆìœ¼ë©´ ì´ˆê¸°í™” (comfy ëª¨ë“ˆ ëˆ„ë½ ë°©ì§€)\n",
    "!git submodule init && git submodule update\n",
    "\n",
    "# í•µì‹¬ ì˜ì¡´ì„± ì„¤ì¹˜\n",
    "# transformers<5.0 ê³ ì •: v5+ì—ì„œ batch_encode_plus ì œê±°ë¨ (Anima tokenizer í˜¸í™˜ ì´ìŠˆ)\n",
    "# deepspeed: diffusion-pipeì˜ í•µì‹¬ í•™ìŠµ í”„ë ˆì„ì›Œí¬\n",
    "!pip install -q deepspeed==0.18.4\n",
    "!pip install -q \"transformers>=4.45,<5.0\" \"diffusers>=0.35.1\" accelerate peft safetensors\n",
    "!pip install -q bitsandbytes torch-optimi pytorch-optimizer\n",
    "!pip install -q toml datasets pillow sentencepiece protobuf\n",
    "!pip install -q tensorboard tqdm einops loguru\n",
    "!pip install -q huggingface_hub\n",
    "\n",
    "!pip install -q imageio[ffmpeg] av omegaconf\n",
    "print(\"âœ… ì˜ì¡´ì„± ì„¤ì¹˜ ì™„ë£Œ\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740b5eae",
   "metadata": {},
   "source": [
    "## 2. ëª¨ë¸ ë‹¤ìš´ë¡œë“œ (HuggingFace â†’ Colab)\n",
    "\n",
    "Anima ëª¨ë¸ 3ê°œ íŒŒì¼ì„ HFì—ì„œ ì§ì ‘ Colab ë¡œì»¬ ìŠ¤í† ë¦¬ì§€ë¡œ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.\n",
    "- **anima-preview.safetensors** â€” Transformer/DiT (~4.2GB)\n",
    "- **qwen_3_06b_base.safetensors** â€” í…ìŠ¤íŠ¸ ì¸ì½”ë” Qwen3-0.6B (~1.2GB)\n",
    "- **qwen_image_vae.safetensors** â€” VAE (~0.2GB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fd4632",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 2-1. Anima ëª¨ë¸ íŒŒì¼ ë‹¤ìš´ë¡œë“œ\n",
    "from huggingface_hub import hf_hub_download\n",
    "import os\n",
    "\n",
    "MODEL_DIR = \"/content/models\"\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "REPO_ID = \"circlestone-labs/Anima\"\n",
    "\n",
    "# Transformer (DiT) â€” anima-preview.safetensors\n",
    "transformer_path = hf_hub_download(\n",
    "    repo_id=REPO_ID,\n",
    "    filename=\"split_files/diffusion_models/anima-preview.safetensors\",\n",
    "    local_dir=MODEL_DIR,\n",
    "    local_dir_use_symlinks=False,\n",
    ")\n",
    "# ì‹¤ì œ ì €ì¥ ê²½ë¡œ ì •ë¦¬\n",
    "TRANSFORMER_PATH = os.path.join(MODEL_DIR, \"split_files/diffusion_models/anima-preview.safetensors\")\n",
    "print(f\"âœ… Transformer: {TRANSFORMER_PATH}\")\n",
    "print(f\"   í¬ê¸°: {os.path.getsize(TRANSFORMER_PATH)/1024**3:.2f} GB\")\n",
    "\n",
    "# Text Encoder â€” qwen_3_06b_base.safetensors\n",
    "text_enc_path = hf_hub_download(\n",
    "    repo_id=REPO_ID,\n",
    "    filename=\"split_files/text_encoders/qwen_3_06b_base.safetensors\",\n",
    "    local_dir=MODEL_DIR,\n",
    "    local_dir_use_symlinks=False,\n",
    ")\n",
    "LLM_PATH = os.path.join(MODEL_DIR, \"split_files/text_encoders/qwen_3_06b_base.safetensors\")\n",
    "print(f\"âœ… Text Encoder: {LLM_PATH}\")\n",
    "print(f\"   í¬ê¸°: {os.path.getsize(LLM_PATH)/1024**3:.2f} GB\")\n",
    "\n",
    "# VAE â€” qwen_image_vae.safetensors\n",
    "vae_path = hf_hub_download(\n",
    "    repo_id=REPO_ID,\n",
    "    filename=\"split_files/vae/qwen_image_vae.safetensors\",\n",
    "    local_dir=MODEL_DIR,\n",
    "    local_dir_use_symlinks=False,\n",
    ")\n",
    "VAE_PATH = os.path.join(MODEL_DIR, \"split_files/vae/qwen_image_vae.safetensors\")\n",
    "print(f\"âœ… VAE: {VAE_PATH}\")\n",
    "print(f\"   í¬ê¸°: {os.path.getsize(VAE_PATH)/1024**3:.2f} GB\")\n",
    "\n",
    "print(f\"\\nğŸ“¦ ëª¨ë¸ ì´ í¬ê¸°: {sum(os.path.getsize(p) for p in [TRANSFORMER_PATH, LLM_PATH, VAE_PATH])/1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2f18df",
   "metadata": {},
   "source": [
    "## 3. Google Drive ë§ˆìš´íŠ¸ ë° ë°ì´í„°ì…‹ ì¤€ë¹„\n",
    "\n",
    "ë°ì´í„°ì…‹ êµ¬ì¡°: ì´ë¯¸ì§€ íŒŒì¼ + ë™ì¼ ì´ë¦„ì˜ `.txt` ìº¡ì…˜ íŒŒì¼  \n",
    "ìº¡ì…˜ í˜•ì‹: Danbooru íƒœê·¸ (ì˜ˆ: `shirakawa yuina, @artist, 1girl, solo, ...`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f510652d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 3-1. Google Drive ë§ˆìš´íŠ¸ + ë°ì´í„°ì…‹ ë³µì‚¬\n",
    "from google.colab import drive\n",
    "import shutil, glob\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# ========================================\n",
    "# âš ï¸ ì—¬ê¸°ë¥¼ ìì‹ ì˜ Google Drive ê²½ë¡œë¡œ ìˆ˜ì •í•˜ì„¸ìš”!\n",
    "# ========================================\n",
    "GDRIVE_DATASET_DIR = \"/content/drive/MyDrive/yuina_anima\"  #@param {type:\"string\"}\n",
    "GDRIVE_OUTPUT_DIR  = \"/content/drive/MyDrive/anima_training_output\"  #@param {type:\"string\"}\n",
    "\n",
    "# ë¡œì»¬ì— ë°ì´í„°ì…‹ ë³µì‚¬ (I/O ì†ë„ í–¥ìƒ)\n",
    "LOCAL_DATASET_DIR = \"/content/dataset\"\n",
    "if os.path.exists(LOCAL_DATASET_DIR):\n",
    "    shutil.rmtree(LOCAL_DATASET_DIR)\n",
    "shutil.copytree(GDRIVE_DATASET_DIR, LOCAL_DATASET_DIR)\n",
    "\n",
    "# ë°ì´í„°ì…‹ í™•ì¸\n",
    "images = sorted(glob.glob(os.path.join(LOCAL_DATASET_DIR, \"*.png\")) +\n",
    "                glob.glob(os.path.join(LOCAL_DATASET_DIR, \"*.jpg\")))\n",
    "captions = sorted(glob.glob(os.path.join(LOCAL_DATASET_DIR, \"*.txt\")))\n",
    "print(f\"ğŸ“ ë°ì´í„°ì…‹ ê²½ë¡œ: {LOCAL_DATASET_DIR}\")\n",
    "print(f\"ğŸ–¼ï¸  ì´ë¯¸ì§€ ìˆ˜: {len(images)}\")\n",
    "print(f\"ğŸ“ ìº¡ì…˜ ìˆ˜:   {len(captions)}\")\n",
    "\n",
    "# ìº¡ì…˜ ë¯¸ë¦¬ë³´ê¸° (ì²« 3ê°œ)\n",
    "print(\"\\n--- ìº¡ì…˜ ë¯¸ë¦¬ë³´ê¸° ---\")\n",
    "for txt_file in captions[:3]:\n",
    "    name = os.path.basename(txt_file)\n",
    "    with open(txt_file, 'r', encoding='utf-8') as f:\n",
    "        content = f.read().strip()\n",
    "    print(f\"  {name}: {content[:120]}{'...' if len(content)>120 else ''}\")\n",
    "\n",
    "# ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±\n",
    "os.makedirs(GDRIVE_OUTPUT_DIR, exist_ok=True)\n",
    "print(f\"\\nğŸ’¾ ê²°ê³¼ ì €ì¥ ê²½ë¡œ: {GDRIVE_OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19575760",
   "metadata": {},
   "source": [
    "## 4. í•™ìŠµ ì„¤ì • íŒŒì¼ ìƒì„± (TOML)\n",
    "\n",
    "ì‚¬ìš©ì ì¡°ì ˆ ê°€ëŠ¥ íŒŒë¼ë¯¸í„°ëŠ” `@param` í¼ìœ¼ë¡œ ì œê³µë©ë‹ˆë‹¤.  \n",
    "**ê³ ì •ê°’** (bf16, activation_checkpointing ë“±)ì€ T4ì—ì„œ ë³€ê²½ ì‹œ NaN/OOM ìœ„í—˜ì´ ìˆì–´ ì½”ë“œ ë‚´ ê³ ì •.\n",
    "\n",
    "> ğŸ’¡ Colabì—ì„œ ì…€ ì™¼ìª½ í¼ì„ í†µí•´ ê°’ì„ ë³€ê²½í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209cc192",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 4-1. dataset.toml ìƒì„±\n",
    "import os\n",
    "\n",
    "# ========================================\n",
    "# ë°ì´í„°ì…‹ ì„¤ì • (@paramìœ¼ë¡œ ì¡°ì ˆ ê°€ëŠ¥)\n",
    "# ========================================\n",
    "RESOLUTION = 512           #@param [512, 768, 1024] {type:\"raw\"}\n",
    "NUM_REPEATS = 2            #@param {type:\"integer\"}\n",
    "CACHE_SHUFFLE_NUM = 1     #@param {type:\"integer\"}\n",
    "MIN_AR = 0.5               #@param {type:\"number\"}\n",
    "MAX_AR = 2.0               #@param {type:\"number\"}\n",
    "NUM_AR_BUCKETS = 7         #@param {type:\"integer\"}\n",
    "\n",
    "dataset_toml = f\"\"\"\n",
    "# Anima LoRA í•™ìŠµ ë°ì´í„°ì…‹ ì„¤ì •\n",
    "\n",
    "resolutions = [{RESOLUTION}]\n",
    "\n",
    "# AR ë²„í‚· ì„¤ì •\n",
    "enable_ar_bucket = true\n",
    "min_ar = {MIN_AR}\n",
    "max_ar = {MAX_AR}\n",
    "num_ar_buckets = {NUM_AR_BUCKETS}\n",
    "\n",
    "# ì´ë¯¸ì§€ ì „ìš©\n",
    "frame_buckets = [1]\n",
    "\n",
    "[[directory]]\n",
    "path = '{LOCAL_DATASET_DIR}'\n",
    "num_repeats = {NUM_REPEATS}\n",
    "cache_shuffle_num = {CACHE_SHUFFLE_NUM}\n",
    "cache_shuffle_delimiter = ', '\n",
    "\"\"\".strip()\n",
    "\n",
    "dataset_toml_path = \"/content/diffusion-pipe/anima_dataset.toml\"\n",
    "with open(dataset_toml_path, 'w') as f:\n",
    "    f.write(dataset_toml)\n",
    "\n",
    "print(f\"âœ… dataset.toml ìƒì„±: {dataset_toml_path}\")\n",
    "print(f\"ğŸ“ í•´ìƒë„: {RESOLUTION}px | repeat: {NUM_REPEATS} | ì…”í”Œ: {CACHE_SHUFFLE_NUM}\")\n",
    "print(\"---\")\n",
    "print(dataset_toml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0519080",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 4-2. í•™ìŠµ ì„¤ì • (training.toml) ìƒì„±\n",
    "import os\n",
    "\n",
    "# ========================================\n",
    "# í•™ìŠµ í•˜ì´í¼íŒŒë¼ë¯¸í„° (@paramìœ¼ë¡œ ì¡°ì ˆ ê°€ëŠ¥)\n",
    "# ========================================\n",
    "EPOCHS = 100               #@param {type:\"integer\"}\n",
    "LORA_RANK = 32             #@param {type:\"integer\"}\n",
    "BLOCKS_TO_SWAP = 8        #@param {type:\"integer\"}\n",
    "SAVE_EVERY_N_EPOCHS = 1   #@param {type:\"integer\"}\n",
    "BATCH_SIZE = 10             #@param [1, 2, 4, 6, 8, 10, 12] {type:\"raw\"}\n",
    "GRAD_ACCUM = 1             #@param [1, 2, 4] {type:\"raw\"}\n",
    "WARMUP_STEPS = 100         #@param {type:\"integer\"}\n",
    "CHECKPOINT_MINUTES = 30    #@param {type:\"integer\"}\n",
    "GRADIENT_CLIPPING = 1.0    #@param {type:\"number\"}\n",
    "LLM_ADAPTER_LR = 0        #@param {type:\"number\"}\n",
    "TIMESTEP_SAMPLE = \"logit_normal\"  #@param [\"logit_normal\", \"uniform\", \"sigmoid\"] {type:\"string\"}\n",
    "\n",
    "# ========================================\n",
    "# Optimizer ì„¤ì •\n",
    "# ========================================\n",
    "OPTIMIZER = \"Prodigy\"      #@param [\"Prodigy\", \"AdamW8bitKahan\", \"adamw_optimi\"] {type:\"string\"}\n",
    "OPTIMIZER_LR = 1           #@param {type:\"number\"}\n",
    "WEIGHT_DECAY = 0.01        #@param {type:\"number\"}\n",
    "\n",
    "# Optimizerë³„ ê¸°ë³¸ ì•ˆë‚´\n",
    "_optim_notes = {\n",
    "    \"Prodigy\": \"lr=1 ê³ ì • (ìë™ LR ì¡°ì •), bf16 í•„ìˆ˜\",\n",
    "    \"AdamW8bitKahan\": \"ì¼ë°˜ì ìœ¼ë¡œ lr=5e-5~5e-6, 8bit ë©”ëª¨ë¦¬ ì ˆì•½\",\n",
    "    \"adamw_optimi\": \"ì¼ë°˜ì ìœ¼ë¡œ lr=2e-5, diffusion-pipe example ê¸°ë³¸ê°’\",\n",
    "}\n",
    "print(f\"ğŸ“‹ Optimizer: {OPTIMIZER} â€” {_optim_notes.get(OPTIMIZER, '')}\")\n",
    "\n",
    "# === Optimizer TOML ë¸”ë¡ ìƒì„± ===\n",
    "if OPTIMIZER == \"Prodigy\":\n",
    "    optimizer_toml = f\"\"\"[optimizer]\n",
    "type = 'Prodigy'\n",
    "lr = {OPTIMIZER_LR}\n",
    "betas = [0.9, 0.99]\n",
    "weight_decay = {WEIGHT_DECAY}\"\"\"\n",
    "elif OPTIMIZER == \"AdamW8bitKahan\":\n",
    "    optimizer_toml = f\"\"\"[optimizer]\n",
    "type = 'AdamW8bitKahan'\n",
    "lr = {OPTIMIZER_LR}\n",
    "betas = [0.9, 0.99]\n",
    "weight_decay = {WEIGHT_DECAY}\"\"\"\n",
    "else:\n",
    "    optimizer_toml = f\"\"\"[optimizer]\n",
    "type = '{OPTIMIZER}'\n",
    "lr = {OPTIMIZER_LR}\n",
    "betas = [0.9, 0.999]\n",
    "weight_decay = {WEIGHT_DECAY}\"\"\"\n",
    "\n",
    "training_toml = f\"\"\"\n",
    "# Anima LoRA Training Config (Colab T4)\n",
    "output_dir = '/content/training_output'\n",
    "dataset = '/content/diffusion-pipe/anima_dataset.toml'\n",
    "\n",
    "# ===== í•™ìŠµ ì„¤ì • =====\n",
    "epochs = {EPOCHS}\n",
    "micro_batch_size_per_gpu = {BATCH_SIZE}\n",
    "pipeline_stages = 1\n",
    "gradient_accumulation_steps = {GRAD_ACCUM}\n",
    "gradient_clipping = {GRADIENT_CLIPPING}\n",
    "warmup_steps = {WARMUP_STEPS}\n",
    "\n",
    "# ===== Block Swap =====\n",
    "blocks_to_swap = {BLOCKS_TO_SWAP}\n",
    "\n",
    "# ===== Eval (ë¹„í™œì„±) =====\n",
    "eval_every_n_epochs = {EPOCHS + 1}\n",
    "eval_before_first_step = false\n",
    "eval_micro_batch_size_per_gpu = 1\n",
    "eval_gradient_accumulation_steps = 1\n",
    "\n",
    "# ===== ì €ì¥ ì„¤ì • =====\n",
    "save_every_n_epochs = {SAVE_EVERY_N_EPOCHS}\n",
    "checkpoint_every_n_minutes = {CHECKPOINT_MINUTES}\n",
    "activation_checkpointing = true\n",
    "partition_method = 'parameters'\n",
    "save_dtype = 'bfloat16'\n",
    "caching_batch_size = 1\n",
    "steps_per_print = 1\n",
    "\n",
    "# ===== ëª¨ë¸ ì„¤ì • (bf16 ê³ ì • â€” fp16ì€ NaN ìœ„í—˜) =====\n",
    "[model]\n",
    "type = 'anima'\n",
    "transformer_path = '{TRANSFORMER_PATH}'\n",
    "vae_path = '{VAE_PATH}'\n",
    "llm_path = '{LLM_PATH}'\n",
    "dtype = 'bfloat16'\n",
    "timestep_sample_method = '{TIMESTEP_SAMPLE}'\n",
    "llm_adapter_lr = {LLM_ADAPTER_LR}\n",
    "\n",
    "# ===== LoRA ì„¤ì • =====\n",
    "[adapter]\n",
    "type = 'lora'\n",
    "rank = {LORA_RANK}\n",
    "dtype = 'bfloat16'\n",
    "\n",
    "# ===== Optimizer =====\n",
    "{optimizer_toml}\n",
    "\"\"\".strip()\n",
    "\n",
    "training_toml_path = \"/content/diffusion-pipe/anima_training.toml\"\n",
    "with open(training_toml_path, 'w') as f:\n",
    "    f.write(training_toml)\n",
    "\n",
    "eff_batch = BATCH_SIZE * GRAD_ACCUM\n",
    "print(f\"âœ… training.toml ìƒì„±: {training_toml_path}\")\n",
    "print(f\"ğŸ“Š Effective batch: {BATCH_SIZE}Ã—{GRAD_ACCUM}={eff_batch} | rank: {LORA_RANK} | swap: {BLOCKS_TO_SWAP}\")\n",
    "print(f\"ğŸ”§ Optimizer: {OPTIMIZER} lr={OPTIMIZER_LR} | warmup: {WARMUP_STEPS} | clip: {GRADIENT_CLIPPING}\")\n",
    "print(f\"ğŸ’¾ Save: every {SAVE_EVERY_N_EPOCHS}ep | checkpoint: {CHECKPOINT_MINUTES}min\")\n",
    "print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa92fcc",
   "metadata": {},
   "source": [
    "## 5. TensorBoard ëª¨ë‹ˆí„°ë§ (Cloudflare Tunnel)\n",
    "\n",
    "í•™ìŠµ ì‹œì‘ **ì „ì—** TensorBoardë¥¼ ë¨¼ì € ë„ì›Œì•¼ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.  \n",
    "Colabì—ì„œëŠ” localhost ì ‘ê·¼ì´ ë¶ˆê°€í•˜ë¯€ë¡œ Cloudflare Tunnelì„ í†µí•´ ì™¸ë¶€ì—ì„œ ì ‘ì†í•©ë‹ˆë‹¤.\n",
    "\n",
    "> ì…€ ì‹¤í–‰ í›„ ì¶œë ¥ë˜ëŠ” `ğŸ”— LINK: https://xxx.trycloudflare.com` ë§í¬ë¥¼ í´ë¦­í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf8ee74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 5-1. TensorBoard ì‹¤í–‰ + Cloudflare Tunnel ì—°ê²°\n",
    "import os, subprocess, socket, threading, time\n",
    "\n",
    "TB_PORT = 6006\n",
    "TB_LOG_DIR = \"/content/training_output\"\n",
    "os.makedirs(TB_LOG_DIR, exist_ok=True)\n",
    "\n",
    "# --- Cloudflare Tunnel ì„¤ì¹˜ ---\n",
    "if not os.path.exists(\"/usr/local/bin/cloudflared\"):\n",
    "    print(\"â˜ï¸  Cloudflare Tunnel ì„¤ì¹˜ ì¤‘...\")\n",
    "    !wget -q -P /tmp/ https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb\n",
    "    !dpkg -i /tmp/cloudflared-linux-amd64.deb\n",
    "    print(\"âœ… Cloudflare Tunnel ì„¤ì¹˜ ì™„ë£Œ\")\n",
    "\n",
    "# --- TensorBoard ë°±ê·¸ë¼ìš´ë“œ ì‹œì‘ ---\n",
    "!kill $(lsof -t -i:{TB_PORT}) 2>/dev/null; true\n",
    "\n",
    "tb_proc = subprocess.Popen(\n",
    "    [\"tensorboard\", \"--logdir\", TB_LOG_DIR, \"--port\", str(TB_PORT), \"--bind_all\"],\n",
    "    stdout=subprocess.PIPE, stderr=subprocess.PIPE\n",
    ")\n",
    "print(f\"ğŸ“Š TensorBoard ì‹œì‘ (port {TB_PORT}, logdir: {TB_LOG_DIR})\")\n",
    "\n",
    "# --- TensorBoard í¬íŠ¸ ëŒ€ê¸° ---\n",
    "print(\"â³ TensorBoard í¬íŠ¸ ëŒ€ê¸° ì¤‘...\")\n",
    "for _ in range(30):\n",
    "    time.sleep(0.5)\n",
    "    sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "    result = sock.connect_ex(('127.0.0.1', TB_PORT))\n",
    "    sock.close()\n",
    "    if result == 0:\n",
    "        break\n",
    "print(\"âœ… TensorBoard ì¤€ë¹„ ì™„ë£Œ!\")\n",
    "\n",
    "# --- Cloudflare Tunnel ì‹œì‘ + URL ë™ê¸°ì ìœ¼ë¡œ ëŒ€ê¸° ---\n",
    "print(\"â˜ï¸  Cloudflare Tunnel ì—°ê²° ì¤‘...\")\n",
    "cf_proc = subprocess.Popen(\n",
    "    [\"cloudflared\", \"tunnel\", \"--url\", f\"http://127.0.0.1:{TB_PORT}\"],\n",
    "    stdout=subprocess.PIPE, stderr=subprocess.PIPE\n",
    ")\n",
    "# stderrì—ì„œ URL ë‚˜ì˜¬ ë•Œê¹Œì§€ ë™ê¸°ì ìœ¼ë¡œ ì½ê¸° (ComfyUI ë°©ì‹)\n",
    "for line in cf_proc.stderr:\n",
    "    l = line.decode()\n",
    "    if \"trycloudflare.com\" in l:\n",
    "        if \"http\" in l:\n",
    "            print(\"ğŸ”— LINK:\", l[l.find(\"http\"):].strip())\n",
    "            print(\"   â†‘ ì´ ë§í¬ë¥¼ í´ë¦­í•˜ë©´ ì‹¤ì‹œê°„ìœ¼ë¡œ lossë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤\")\n",
    "            break\n",
    "\n",
    "print(\"\\nğŸ“Œ ë§í¬ í™•ì¸ í›„ ë‹¤ìŒ ì…€(í•™ìŠµ ì‹œì‘)ì„ ì‹¤í–‰í•˜ì„¸ìš”.\")\n",
    "print(\"   TensorBoard + Tunnelì€ ë°±ê·¸ë¼ìš´ë“œë¡œ ê³„ì† ë™ì‘í•©ë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ab5e9c",
   "metadata": {},
   "source": [
    "## 6. í•™ìŠµ ì‹¤í–‰\n",
    "\n",
    "DeepSpeedë¥¼ í†µí•´ diffusion-pipe í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
    "\n",
    "**ì‹¤í–‰ íë¦„:**\n",
    "1. Latent ìºì‹± (VAEë¡œ ì´ë¯¸ì§€ â†’ latent ë³€í™˜, 1íšŒë§Œ)\n",
    "2. Text embedding ìºì‹± (Qwen3ë¡œ ìº¡ì…˜ â†’ embedding, 1íšŒë§Œ)  \n",
    "3. LoRA í•™ìŠµ ì‹œì‘\n",
    "\n",
    "> ğŸ“Š ìœ„ì—ì„œ ì‹¤í–‰í•œ TensorBoard ë§í¬ì—ì„œ ì‹¤ì‹œê°„ lossë¥¼ ëª¨ë‹ˆí„°ë§í•˜ì„¸ìš”!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcf768b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 6-1. í•™ìŠµ ì‹œì‘\n",
    "import os\n",
    "os.chdir('/content/diffusion-pipe')\n",
    "os.environ['PYTORCH_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "\n",
    "!NCCL_P2P_DISABLE=\"1\" NCCL_IB_DISABLE=\"1\" \\\n",
    "    deepspeed --num_gpus=1 train.py \\\n",
    "    --deepspeed \\\n",
    "    --config anima_training.toml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2bb1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 6-2. (ì„ íƒ) ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì´ì–´ í•™ìŠµ (Colab ëŠê¹€ í›„)\n",
    "# ============================================================\n",
    "# ìƒˆ Colab ì„¸ì…˜ì—ì„œì˜ ì´ì–´ í•™ìŠµ ìˆœì„œ:\n",
    "#   1. ì…€ 1~5 ìˆœì„œëŒ€ë¡œ ì‹¤í–‰ (í™˜ê²½ ì„¤ì •, ëª¨ë¸ ë‹¤ìš´ë¡œë“œ, Drive ë§ˆìš´íŠ¸, TOML ìƒì„±, TensorBoard)\n",
    "#   2. ì´ ì…€ ì‹¤í–‰ (Driveì—ì„œ ì²´í¬í¬ì¸íŠ¸ ë³µì› + ì´ì–´ í•™ìŠµ)\n",
    "# ============================================================\n",
    "\n",
    "import os, shutil, glob, re\n",
    "\n",
    "# --- Google Driveì—ì„œ ì²´í¬í¬ì¸íŠ¸ ë³µì› ---\n",
    "OUTPUT_DIR = \"/content/training_output\"\n",
    "GDRIVE_OUTPUT_DIR = \"/content/drive/MyDrive/anima_training_output\"  # ì…€ 3ì—ì„œ ì„¤ì •í•œ ê²½ë¡œì™€ ë™ì¼í•˜ê²Œ!\n",
    "\n",
    "def sort_by_step(path):\n",
    "    \"\"\"global_step í´ë”ë¥¼ ìˆ«ì ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬ (global_step80 < global_step473)\"\"\"\n",
    "    m = re.search(r'(\\d+)$', os.path.basename(path))\n",
    "    return int(m.group(1)) if m else 0\n",
    "\n",
    "# Driveì— ë°±ì—…ëœ í•™ìŠµ ê²°ê³¼ê°€ ìˆìœ¼ë©´ ë¡œì»¬ë¡œ ë³µì›\n",
    "if os.path.exists(GDRIVE_OUTPUT_DIR) and os.listdir(GDRIVE_OUTPUT_DIR):\n",
    "    print(\"ğŸ”„ Google Driveì—ì„œ ì²´í¬í¬ì¸íŠ¸ ë³µì› ì¤‘...\")\n",
    "    if os.path.exists(OUTPUT_DIR):\n",
    "        shutil.rmtree(OUTPUT_DIR)\n",
    "    shutil.copytree(GDRIVE_OUTPUT_DIR, OUTPUT_DIR)\n",
    "    print(f\"âœ… ë³µì› ì™„ë£Œ: {GDRIVE_OUTPUT_DIR} â†’ {OUTPUT_DIR}\")\n",
    "\n",
    "    # ê°€ì¥ ìµœê·¼ run ìë™ íƒì§€ (diffusion-pipeì™€ ë™ì¼ ë°©ì‹: sorted glob â†’ ë§ˆì§€ë§‰)\n",
    "    run_dirs = sorted(glob.glob(os.path.join(OUTPUT_DIR, \"*\")))\n",
    "    if run_dirs:\n",
    "        latest_run = run_dirs[-1]\n",
    "        print(f\"\\nğŸ“‚ ìµœì‹  run: {os.path.basename(latest_run)}\")\n",
    "        for item in sorted(os.listdir(latest_run)):\n",
    "            marker = \"ğŸ“\" if os.path.isdir(os.path.join(latest_run, item)) else \"ğŸ“„\"\n",
    "            print(f\"   {marker} {item}\")\n",
    "\n",
    "        # global_step ì²´í¬í¬ì¸íŠ¸ í™•ì¸ (ìˆ«ì ê¸°ì¤€ ì •ë ¬!)\n",
    "        ckpts = sorted(glob.glob(os.path.join(latest_run, \"global_step*\")), key=sort_by_step)\n",
    "        if ckpts:\n",
    "            latest_ckpt = os.path.basename(ckpts[-1])\n",
    "            print(f\"\\nğŸ”„ ì´ì–´ í•™ìŠµ ì‹œì‘ì : {latest_ckpt}\")\n",
    "        else:\n",
    "            print(\"\\nâš ï¸ DeepSpeed ì²´í¬í¬ì¸íŠ¸(global_step*)ê°€ ì—†ìŠµë‹ˆë‹¤. ì²˜ìŒë¶€í„° í•™ìŠµë©ë‹ˆë‹¤.\")\n",
    "\n",
    "        # latest íŒŒì¼ í™•ì¸ (DeepSpeedê°€ ì‹¤ì œë¡œ ì½ëŠ” íŒŒì¼)\n",
    "        latest_file = os.path.join(latest_run, \"latest\")\n",
    "        if os.path.exists(latest_file):\n",
    "            with open(latest_file, 'r') as f:\n",
    "                ds_tag = f.read().strip()\n",
    "            print(f\"   (DeepSpeed latest íŒŒì¼: {ds_tag})\")\n",
    "else:\n",
    "    print(\"âš ï¸ Google Driveì— ë°±ì—…ëœ ì²´í¬í¬ì¸íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "    print(f\"   ê²½ë¡œ í™•ì¸: {GDRIVE_OUTPUT_DIR}\")\n",
    "\n",
    "# --- ì´ì–´ í•™ìŠµ ì‹œì‘ ---\n",
    "# --resume_from_checkpoint: diffusion-pipeê°€ ìë™ìœ¼ë¡œ output_dir ë‚´ ìµœì‹  run â†’ latest íŒŒì¼ â†’ ì²´í¬í¬ì¸íŠ¸ íƒì§€\n",
    "os.chdir('/content/diffusion-pipe')\n",
    "os.environ['PYTORCH_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "\n",
    "!NCCL_P2P_DISABLE=\"1\" NCCL_IB_DISABLE=\"1\" \\\n",
    "    deepspeed --num_gpus=1 train.py \\\n",
    "    --deepspeed \\\n",
    "    --config anima_training.toml \\\n",
    "    --resume_from_checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900887b9",
   "metadata": {},
   "source": [
    "## 7. ê²°ê³¼ í™•ì¸ ë° Google Driveë¡œ ë‚´ë³´ë‚´ê¸°\n",
    "\n",
    "í•™ìŠµ ì™„ë£Œ í›„ LoRA íŒŒì¼ì„ Google Driveì— ë³µì‚¬í•©ë‹ˆë‹¤.\n",
    "- ì €ì¥ í˜•ì‹: **ComfyUI í˜¸í™˜** (`diffusion_model.` prefix í‚¤ í¬í•¨)\n",
    "- ComfyUIì—ì„œ LoRA ë…¸ë“œë¡œ ë°”ë¡œ ì‚¬ìš© ê°€ëŠ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a866fb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 7-1. í•™ìŠµ ê²°ê³¼ Google Drive ë°±ì—… (í•™ìŠµ ì¤‘ì—ë„ ì‹¤í–‰ ê°€ëŠ¥!)\n",
    "# âš ï¸ Colab ì„¸ì…˜ ì¢…ë£Œ ì „ì— ë°˜ë“œì‹œ ì‹¤í–‰í•˜ì„¸ìš”!\n",
    "# í•™ìŠµ ì¤‘ì´ë¼ë„ ë‹¤ë¥¸ ì…€ì—ì„œ ì‹¤í–‰ ê°€ëŠ¥í•©ë‹ˆë‹¤.\n",
    "import glob, shutil, os, re\n",
    "\n",
    "OUTPUT_DIR = \"/content/training_output\"\n",
    "GDRIVE_OUTPUT_DIR = \"/content/drive/MyDrive/anima_training_output\"  # ì…€ 3ì—ì„œ ì„¤ì •í•œ ê²½ë¡œì™€ ë™ì¼í•˜ê²Œ!\n",
    "\n",
    "# í•™ìŠµ ê²°ê³¼ í´ë” ì°¾ê¸° (ê°€ì¥ ìµœì‹  run â€” diffusion-pipeì™€ ë™ì¼ ë°©ì‹)\n",
    "run_dirs = sorted(glob.glob(os.path.join(OUTPUT_DIR, \"*\")))\n",
    "if not run_dirs:\n",
    "    print(\"âŒ í•™ìŠµ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "else:\n",
    "    latest_run = run_dirs[-1]\n",
    "    print(f\"ğŸ“‚ ìµœì‹  í•™ìŠµ run: {os.path.basename(latest_run)}\\n\")\n",
    "\n",
    "    # ì €ì¥ëœ LoRA epoch í™•ì¸\n",
    "    lora_dirs = sorted(glob.glob(os.path.join(latest_run, \"epoch*\")), key=lambda x: int(re.search(r'(\\d+)', os.path.basename(x)).group(1)))\n",
    "    print(f\"ğŸ“¦ ì €ì¥ëœ LoRA ì²´í¬í¬ì¸íŠ¸: {len(lora_dirs)}ê°œ\")\n",
    "    for d in lora_dirs:\n",
    "        safetensors = os.path.join(d, \"adapter_model.safetensors\")\n",
    "        if os.path.exists(safetensors):\n",
    "            size_mb = os.path.getsize(safetensors) / 1024**2\n",
    "            print(f\"   {os.path.basename(d)}/adapter_model.safetensors ({size_mb:.1f} MB)\")\n",
    "\n",
    "    # DeepSpeed ì²´í¬í¬ì¸íŠ¸ í™•ì¸ (ì´ì–´ í•™ìŠµìš© â€” global_step* í´ë”)\n",
    "    ckpt_dirs = sorted(glob.glob(os.path.join(latest_run, \"global_step*\")), key=lambda x: int(re.search(r'(\\d+)', os.path.basename(x)).group(1)))\n",
    "    if ckpt_dirs:\n",
    "        total_ckpt_size = sum(\n",
    "            sum(os.path.getsize(os.path.join(dp, f)) for f in fnames)\n",
    "            for cd in ckpt_dirs for dp, _, fnames in os.walk(cd)\n",
    "        ) / 1024**3\n",
    "        print(f\"\\nğŸ”„ DeepSpeed ì²´í¬í¬ì¸íŠ¸: {len(ckpt_dirs)}ê°œ (ì´ì–´ í•™ìŠµìš©, ì´ {total_ckpt_size:.1f} GB)\")\n",
    "        for cd in ckpt_dirs:\n",
    "            print(f\"   ğŸ“ {os.path.basename(cd)}\")\n",
    "    else:\n",
    "        print(\"\\nâš ï¸ DeepSpeed ì²´í¬í¬ì¸íŠ¸ ì—†ìŒ (ì´ì–´ í•™ìŠµ ë¶ˆê°€)\")\n",
    "\n",
    "    # TensorBoard ë¡œê·¸ í™•ì¸\n",
    "    tb_files = glob.glob(os.path.join(latest_run, \"events.out.tfevents*\"))\n",
    "    if tb_files:\n",
    "        print(f\"\\nğŸ“Š TensorBoard ë¡œê·¸: {len(tb_files)}ê°œ\")\n",
    "\n",
    "    # Google Driveë¡œ ë³µì‚¬ (run í´ë” ì „ì²´ = LoRA + ì²´í¬í¬ì¸íŠ¸ + TB ë¡œê·¸ + TOML)\n",
    "    print(f\"\\nğŸ”„ Google Driveë¡œ ë³µì‚¬ ì¤‘... â†’ {GDRIVE_OUTPUT_DIR}\")\n",
    "    os.makedirs(GDRIVE_OUTPUT_DIR, exist_ok=True)\n",
    "    dest = os.path.join(GDRIVE_OUTPUT_DIR, os.path.basename(latest_run))\n",
    "    if os.path.exists(dest):\n",
    "        shutil.rmtree(dest)\n",
    "    shutil.copytree(latest_run, dest)\n",
    "\n",
    "    # ë³µì‚¬ ê²°ê³¼ ìš”ì•½\n",
    "    dest_size = sum(\n",
    "        os.path.getsize(os.path.join(dp, f))\n",
    "        for dp, _, fnames in os.walk(dest) for f in fnames\n",
    "    ) / 1024**3\n",
    "    print(f\"âœ… ë³µì‚¬ ì™„ë£Œ: {dest} ({dest_size:.1f} GB)\")\n",
    "    print(f\"   í¬í•¨: LoRA({len(lora_dirs)}) + ì²´í¬í¬ì¸íŠ¸({len(ckpt_dirs)}) + TensorBoard + TOML\")\n",
    "\n",
    "    if lora_dirs:\n",
    "        print(f\"\\nğŸ¯ ìµœì¢… LoRA: {os.path.basename(lora_dirs[-1])}/adapter_model.safetensors\")\n",
    "        print(\"   â†’ ComfyUIì˜ loras/ í´ë”ì— ë„£ì–´ì„œ ì‚¬ìš©í•˜ì„¸ìš”\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be285a8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“Œ íŠ¸ëŸ¬ë¸”ìŠˆíŒ… & íŒ\n",
    "\n",
    "### VRAM OOMì´ ë°œìƒí•˜ë©´\n",
    "1. `BLOCKS_TO_SWAP`ì„ `14`~`18`ë¡œ ì˜¬ë¦¬ê¸° (ìµœëŒ€ 26)\n",
    "2. `resolutions`ë¥¼ `[512]`ë¡œ ë‚®ì¶”ê¸°\n",
    "3. `activation_checkpointing = 'unsloth'`ë¡œ ë³€ê²½ (ë” ê³µê²©ì  ì ˆì•½)\n",
    "\n",
    "### í•™ìŠµì´ ë„ˆë¬´ ëŠë¦¬ë©´\n",
    "- `blocks_to_swap`ì„ ì¤„ì´ê¸° (VRAMì´ ì—¬ìœ  ìˆë‹¤ë©´)\n",
    "- `gradient_accumulation_steps`ë¥¼ 2ë¡œ ë‚®ì¶”ê¸°\n",
    "\n",
    "### ê³¼ì í•© ì²´í¬\n",
    "- Lossê°€ ì´ˆë°˜ì— ë¹ ë¥´ê²Œ ë–¨ì–´ì§„ í›„ ë” ì´ìƒ ê°ì†Œí•˜ì§€ ì•Šìœ¼ë©´ ê³¼ì í•© ê°€ëŠ¥ì„±\n",
    "- `save_every_n_epochs = 5`ë¡œ ì¤„ì—¬ì„œ ì¤‘ê°„ ì²´í¬í¬ì¸íŠ¸ ì €ì¥\n",
    "- ComfyUIì—ì„œ ê° epochì˜ LoRAë¥¼ ì§ì ‘ ëˆˆìœ¼ë¡œ ë¹„êµí•˜ëŠ” ê²ƒì´ ê°€ì¥ í™•ì‹¤\n",
    "\n",
    "### ìº¡ì…˜ ê´€ë ¨\n",
    "- Anima íƒœê·¸ ìˆœì„œ: `[quality/meta] [1girl/1boy] [character] [series] [artist] [general tags]`\n",
    "- ì•„í‹°ìŠ¤íŠ¸ íƒœê·¸ëŠ” ë°˜ë“œì‹œ `@` ì ‘ë‘ì‚¬: `@artistname`\n",
    "- ìº¡ì…˜ ë¶€ì¡± ì‹œ ë¹ˆ ìº¡ì…˜ìœ¼ë¡œ í•™ìŠµë¨ (ê²½ê³ ë§Œ ì¶œë ¥)\n",
    "\n",
    "### Colab ì„¸ì…˜ ëŠê¹€ ëŒ€ë¹„\n",
    "- `checkpoint_every_n_minutes = 30`ì´ ì„¤ì •ë˜ì–´ ìˆìŒ\n",
    "- ëŠê¸°ë©´ ì…€ 1~4 ì¬ì‹¤í–‰ í›„ **5-2 ì…€ (ì´ì–´ í•™ìŠµ)** ì‹¤í–‰"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
